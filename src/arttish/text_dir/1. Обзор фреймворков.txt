Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? Какие модели используются для анализирования изображений? точный, более понятный код, соответственно, придерживаться лучших практик разработки таких приложений. Ну и помимо этого, также немаловажный фактор, чтобы кроме того, что нам фреймворк сам дает, мы могли как-то более гибко его использовать, это расширяемость. Соответственно, мы можем сами добавить какой-то функционал, и сделать это достаточно просто в парадигме использования такого модульного многокомпонентного приложения, что действительно расширяет значительно возможности использования таких фреймворков и приложений на базе этих фреймворков. Ну и рассмотрим некоторые ключевые фреймворки. Как я уже сказал, фреймворков и различных библиотек, которые упрощают взаимодействие с LL-моделями в настоящее время огромное количество, их все, наверное, даже и не перечислишь, и не упомнишь, но тем не менее, есть некоторые, которые все знают, которые пользуются большой популярностью, и которые действительно хорошо решают свои задачи. Итак, первый фреймворк, о котором мы поговорим, это UncChain. Он отвечает за регистрацию и создание LL-пайплайнов. И это фреймворк, наверное, который появился одним из первых для упрощения доступа к LL-моделям, и он позволяет строить различные сложные приложения на базе LL-моделей через цепочки операций. Поскольку у нас LL-модель это не просто какой-то одиночный запрос к LL-модели, это обычно некоторая последовательность вызовов. Помимо последовательности вызовов LL-моделей также используются некоторые другие операции, которые тоже необходимо выполнять в процессе обработки запросов. И в связи с этим, как раз такой подход, когда у нас есть цепочка операций, он оказался действительно очень хорошим и очень полезным в использовании. Помимо цепочек, UncChain также позволяет использовать компоненты, которые довольно-таки легко и просто можно заменять и экспериментировать. Также UncChain добавляет элемент, компонент памяти, который позволяет упростить создание линейных линейок, упростить создание различных приложений диалоговых, поскольку позволяет управлять историей разговора, позволяет модели поддерживать контекст взаимодействия с пользователем и так далее. Ну и помимо этого, также популярное сейчас направление это агенты. Это некоторые автономные сущности, которые могут взаимодействовать с какой-то внешней средой, получать данные и на основе этих данных решать некоторую задачу. Обычно такие сущности используют методологию REACT, RISM, THEN ACT, соответственно, рассуждая действуй. Таким образом наши такие агенты, они могут не только обрабатывать какие-то запросы, они могут принимать решения на их уровне, каким образом в данный момент поступить, и соответственно у них есть возможность выполнить какое-то действие, либо обратиться к другой какой-то системе или агенту, получить какую-то информацию, либо дать какую-то обратную связь пользователю и так далее. В целом онлайн-чейн мы далее рассмотрим более подробно, однако следует выделить некоторые преимущества и недостатки, которыми обладает этот фреймворк. Ну в первую очередь он очень гибкий и настраиваемый, в нем действительно очень много уже различных готовых компонентов, которые обеспечивают доступ как ко всем современным моделям, современным векторным базам данных и так далее. Он позволяет и дописывать эти компоненты под свои нужды, как угодно, очень удобный, очень гибкий. Помимо этого присутствует обширная документация, которая позволяет как познакомиться с таким базовым использованием этого фреймворка, так же и разобраться во всех деталях его использования. Ну и помимо этого он действительно очень активно используется, и вот эта экосистема, которая устраивается, вокруг него она тоже очень обширная и очень быстро растущая. К недостаткам можно отнести то, что первоначально может возникнуть некоторая сложность с изучением этого фреймворка, поскольку он уже довольно-таки разросся и действительно там очень много функционала сейчас. Ну и также требуется понимание того, какое приложение мы хотим выстроить, того, как оно будет функционировать, чтобы построить правильные цепочки, чтобы они взаимодействовали именно так, как мы хотим. Следующим фреймворком является Lama Index, и можно сказать, что это фреймворк, который сфокусирован на предоставлении LLAM доступа к некоторым данным. И в данном случае подразумеваются в основном именно какие-то закрытые приватные данные, поскольку современные LLAM модели обладают очень широким спектром, они действительно хорошо владеют информацией в различных областях, тем не менее какие-то внутренние данные компаний или какие-то еще источники, они, конечно же, закрыты, и о них информации у моделей может не быть. К тому же это могут быть какие-то данные, которые защищаются различными лицензиями, товарными лицензиями, те данные, о которых модель тоже не имеет возможности как-то рассуждать, говорить и так далее. И в этом случае как раз-таки помогают различные фреймворки, которые позволяют обеспечить такое взаимодействие с данными. Это подход напрямую связанный с генерацией дополненной поиском или Retrieval Augmented Generation. Соответственно, здесь у нас присутствуют некоторые элементы, называемые коннекторами данных, которые позволяют, нам извлекать вот эти данные из различных источников, что очень полезно. Далее у нас есть компонент индексации, который позволяет эти полученные данные эффективным образом хранить и производить по ним точный поиск. Помимо этого в фреймворке присутствуют довольно-таки мощные поисковые движки, которые позволяют осуществлять как полнотекстовый поиск, так и семантический поиск. И в целом сам фреймворк сфокусирован на том, чтобы обеспечивать очень высокую точность поиска и скорость поиска. Ну и помимо этого обеспечивает возможность реализации довольно-таки быстрой и простой как раз-таки генерации дополненной поиском. Соответственно, к преимуществам относится то, что у нас действительно упрощается процесс подключения LLAM к нашим каким-то внутренним данным, предоставляет инструменты, которые, позволяет построить приложение, которое будет масштабируемым и обеспечивать высокое качество поиска, при этом обладает некоторой сложностью при настройке этого поиска, то есть мы действительно можем достичь хороших результатов, но для того, чтобы нам этих результатов достичь, нам все равно необходимо понимать, что из себя представляют различные индексы и в каких случаях нам следует использовать тот или иной вариант индекса и вариант поиска. Ну и также за настройку промптов тоже отвечает пользователь, соответственно, то, насколько наш LLAM хорошо будет отвечать на поставленные запросы по данным, будет зависеть в том числе и от того, как хорошо эти промпты настроены. Следующий фреймворк более свежий, более актуальный, но в какой-то мере и более сложный, он сфокусирован на интеграции агентов искусственного интеллекта в приложение, соответственно, здесь уже у нас основной фокус как раз-таки на наших AI-агентах. Для этого у нас формируются некоторые навыки, которые мы хотим использовать, и эти навыки интегрируются в некоторый процесс обработки. Для этого, во-первых, формируются сами навыки в виде некоторых модульных единиц, которые выполняют определенные процедуры, определенный набор операций, в том числе и с использованием LLAM-моделей. Далее эти навыки управляются планировщиками, то есть планировщик обеспечивает использование навыков автоматическое для решения той или иной задачи. Для этого присутствуют коннекторы для работы с различными внешними сервисами и API, соответственно, у нас уже появляется навык. По сути, это некоторый агент, который работает на нашей сети. который, во-первых, умеет решать какую-то определенную задачу, и при этом для решения этой задачи может обращаться к каким-то сторонним источникам. Этим всем управляет планировщик, а работает это все благодаря ядру, в котором как раз-таки у нас работают все наши агенты, и которые управляют взаимодействием этих агентов между собой в соответствии с нашим планировщиком. Ну и, конечно же, этот подход нам обеспечивает хорошее переиспользование кода и модульности, поскольку вот эти вот навыки, они легко переносятся, эти агенты, их можно легко переиспользовать в различных приложениях, при этом это упрощает создание более сложных приложений на базе таких агентов искусственного интеллекта. Получается довольно гибкая, довольно-таки понятная архитектура, в которой можно свои нужды видоизменять. Которая легко подстраивается под нужды приложения, которые вы разрабатываете. Однако такая функциональность, она действительно может быть довольно-таки сложной в настройке. Плюс сами навыки необходимо разрабатывать, прописывать изначально. Есть некоторые готовые навыки, которые можно взять, над которыми работает сообщество. Однако сам фреймворк, он относительно новый, значительно новее, чем мы его используем. Ланкчейн и лама индекс. Поэтому документация и та поддержка сообщества, которая на данный момент есть, они все еще оставляют желать лучшего. Соответственно, сами навыки необходимо будет по большей части прописывать отдельно. Но далее, когда у нас уже есть готовая база для решения различных задач, мы можем довольно-таки большой спектр применений таким образом покрыть. Ну и последнее, о чем мы сегодня поговорим, это хакинфейс трансформер. Это уже у нас не фреймворк, это библиотека. При этом можно сказать, что это всеобъемлющая библиотека для работы с предобученными моделями на основе архитектуры трансформер. Архитектура трансформер, это в принципе самая основа основ для больших языковых моделей. Поскольку в принципе кажется нет ни одной большой языковой модели, которая бы не была построена на архитектуре трансформер. И библиотека. Библиотека трансформер, она объединяет в себе все, что только можно вокруг этих моделей. То есть она предоставляет доступ к самим этим моделям. Можно их скачать, можно ими попользоваться и так далее. Она позволяет получить доступ и к тем данным, на которых обучаются эти модели. Помимо этого, она дает доступ к pipeline, которые уже настроены для решения каких-то распространенных задач. Очень простым образом, буквально из коробки, с использованием той модели, которую мы хотим, тех данных, которые мы хотим и так далее. Действительно, достаточно быстро и просто можно решить какую-то типовую NLP задачу. Помимо этого, присутствуют, помимо самих моделей, также токенизаторы, которые позволяют преобразовывать текст в численный вид, с которым работают модели. Быстро и эффективно. Ну и помимо этого, то, что позволяет делать библиотека и не могут дать доступ к фреймворке, это обучение и дообучение моделей. Если нам необходимо как-то скорректировать модель под свои нужды, то здесь нам, скорее всего, пригодится библиотека Transformers или некоторые библиотеки, которые тоже присутствуют, которые также можно использовать. Соответственно, если мы говорим про преимущества и недостатки, то Cogginface Transformers это действительно уже очень хорошо проработанная, развившаяся, поддерживаемая библиотека с очень активным сообществом. Она дает возможность использования очень широкого спектра функций. По ней сформировалась очень хорошая документация, есть целый курс от Cogginface по использованию этих моделей, по всему, что только там есть. Можно найти архитектуру любой модели, посмотреть, из каких блоков она состоит, какие функции обучения там используются и так далее. Однако при этом мы работаем действительно на таком низком уровне. Мы должны понимать, что из себя представляют модели, как они обучаются, какие данные могут использоваться. В общем, всю базу машинного обучения, глубокого обучения мы должны знать, для того чтобы работать с этими моделями. Ну и помимо этого, конечно же, использование такого подхода, прямого доступа к моделям, оно заметно сложнее, чем тот же лонгчейн или лама индекс. Ну и подводя некоторый итог, говоря про выбор того или иного фреймворка под решаемые задачи, если нам нужно выполнить какой-то сложный процесс с помощью LLM, построить некоторые конвейеры обработки данных, конвейеры обработки запросов и так далее, то здесь хорошо подходит лонгчейн. К тому же сейчас в лонгчейне также присутствует довольно-таки неплохой функционал для разработки приложений на основе агентов. Если у нас необходимость обеспечить исключительно доступ к каким-то данным, то есть прям какой-то чистый рак, то это лама индекс. Если необходимо создать каких-то более сложных, более интеллектуальных агентов, автоматизировать какие-то более сложные рабочие процессы с доступом к различным внешним источникам, то тут хорошо подойдет Semantic Kernel. Ну а в случае, когда нам необходимо использовать лонгчейн, то мы необходим какой-то низкоуровневый доступ к обучению моделей, разработке моделей, или мы прям хотим четко контролировать процесс работы модели на низком уровне, допустим, мы хотим применить какие-то параметрически эффективные методы для обучения и так далее, то для этого лучше всего использовать Hering Face Transformers библиотеку.